{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a1264f3",
   "metadata": {},
   "source": [
    "# Multiprocessing package in Python\n",
    "\n",
    "Multiprocessing is a package in Python for creating and managing processes. It is a part of the Python standard library and is used for parallel processing. Find documentation [here](https://docs.python.org/3/library/multiprocessing.html).\n",
    "\n",
    "The below code cells demonstrate how to use the `multiprocessing` package in Python with a very simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189c5f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "import time\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878e0074-186d-41c7-a5b3-7ff0aebc2e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(arg):\n",
    "    # generate a random value between 0 and 1\n",
    "    value = random()\n",
    "    # pause the process for a fraction of a second\n",
    "    time.sleep(value)\n",
    "    # report a message\n",
    "    print(f'.done {arg}, generated {value}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e8ecb-b5f2-4ff5-947f-de7852552a8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the task a number of times sequentially using a for loop\n",
    "if __name__ == '__main__':\n",
    "    # run tasks sequentially\n",
    "    for i in range(20):\n",
    "        task(i)\n",
    "    print('Done', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9acd89a-4459-4782-87c4-53cdc7c24963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the task a number of times in parallel using multiprocessing\n",
    "if __name__ == '__main__':\n",
    "    # create all tasks\n",
    "    processes = [Process(target=task, args=(i,)) for i in range(20)]\n",
    "    # start all processes\n",
    "    for process in processes:\n",
    "        process.start()\n",
    "    # wait for all processes to complete\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "    # report that all tasks are completed\n",
    "    print('Done', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad793ce7",
   "metadata": {},
   "source": [
    "The above code is not ideal because it might start more processes than the number of cores available on the machine. We can improve this by creating batches of processes and running these batches in parallel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ca263-2948-484d-897c-83ef0003ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the task a number of times in batches using multiprocessing\n",
    "if __name__ == '__main__':\n",
    "    # define batch size\n",
    "    batch_size = 8\n",
    "    # execute in batches\n",
    "    for i in range(0, 20, batch_size):\n",
    "        # execute all tasks in a batch\n",
    "        processes = [Process(target=task, args=(j,)) for j in range(i, i+batch_size)]\n",
    "        # start all processes\n",
    "        for process in processes:\n",
    "            process.start()\n",
    "        # wait for all processes to complete\n",
    "        for process in processes:\n",
    "            process.join()\n",
    "    # report that all tasks are completed\n",
    "    print('Done', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164d4ac5-7c3b-42fa-a266-0ff54e95a3ac",
   "metadata": {},
   "source": [
    "Another (and probably cleaner) way to achieve this is to use a Pool of workers. The Pool class provides a way to distribute tasks across multiple processes. The Pool class has a map method that can be used to apply a function to a list of arguments. The map method blocks until all tasks are completed. If this sounds interesting to you, you can read more about it [here](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool), and try to implement it yourself below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d659d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14c94a99",
   "metadata": {},
   "source": [
    "Now, let's see if we can do the same with a function that actually does something useful. The function below estimate pi using the Monte Carlo method. The idea is to generate random points in a square and count how many of them fall inside a circle. The ratio of the number of points inside the circle to the total number of points is an estimate of pi/4. The more points we generate, the better the estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c0c5f8-d0c1-4692-99c9-c4be6da1f829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pi(N):\n",
    "    M = 0\n",
    "    for i in range(N):\n",
    "        # Simulate impact coordinates\n",
    "        x = np.random.uniform(-1, 1)\n",
    "        y = np.random.uniform(-1, 1)\n",
    "\n",
    "        # True if impact happens inside the circle\n",
    "        if x**2 + y**2 < 1.0:\n",
    "            M += 1\n",
    "    return (4 * M / N, N)  # result, iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b5778-fef7-4f5c-abe5-2af304a1749b",
   "metadata": {},
   "source": [
    "Try to parallelize the code using the Pool class from the multiprocessing package. And compare the time it takes to run the code with and without parallelization. Try to measure the speedup you get from parallelization. It might be that you run into issues when trying to use multiprocessing in a Jupyter notebook. If that is the case, you can try to run the code in a Python script instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94dffa0",
   "metadata": {},
   "source": [
    "Optional: a more detailed explanation and examples of this problem can be found [here](https://carpentries-incubator.github.io/lesson-parallel-python/04b-threads-and-processes/index.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
